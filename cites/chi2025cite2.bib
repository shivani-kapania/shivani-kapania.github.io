@inproceedings{10.1145/3706598.3714010,
author = {Abdelkadir, Nuredin Ali and Yang, Tianling and Kapania, Shivani and Estefanos, Meron and Gebrekidan, Fasica Berhane and Zelalem, Zecharias and Ali, Messai and Berhe, Rishan and Baker, Dylan and Talat, Zeerak and Miceli, Milagros and Hanna, Alex and Gebru, Timnit},
title = {The Role of Expertise in Effectively Moderating Harmful Social Media Content},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714010},
doi = {10.1145/3706598.3714010},
abstract = {Social media platforms played a significant role in spreading genocidal content in the 2020-2022 Tigray war, where the deadliest genocide of the 21st century was committed. While linguistic expertise is clearly needed to adequately moderate such content, we ask: What additional expertise is needed? Why and to what extent do experts disagree on what constitutes harmful content, and what is the best way to resolve these disagreements? What do social media platforms do instead? We examine these questions through a 4-month study with 7 experts labeling 340 X (formerly Twitter) posts, and by interviewing 15 commercial content moderators. We find in-depth cultural knowledge and dialects to be most important for accurate hate speech annotation â€“ knowledge which social media platforms do not prioritize. Even amongst experts, disagreements are high (71\%), dropping to 40\% after deliberation meetings. Based on these results, we present 7 recommendations to improve hate speech annotation and moderation practices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {227},
numpages = {21},
keywords = {Expertise, Content Moderation, Data Annotation, Expert Disagreement, Harmful Content, Social Media Platforms},
location = {
},
series = {CHI '25}
}