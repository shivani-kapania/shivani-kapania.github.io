@inproceedings{10.1145/3706598.3713220,
author = {Kapania, Shivani and Agnew, William and Eslami, Motahhare and Heidari, Hoda and Fox, Sarah E},
title = {Simulacrum of Stories: Examining Large Language Models as Qualitative Research Participants},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713220},
doi = {10.1145/3706598.3713220},
abstract = {The recent excitement around generative models has sparked a wave of proposals suggesting the replacement of human participation and labor in research and development–e.g., through surveys, experiments, and interviews—with synthetic research data generated by large language models (LLMs). We conducted interviews with 19 qualitative researchers to understand their perspectives on this paradigm shift. Initially skeptical, researchers were surprised to see similar narratives emerge in the LLM-generated data when using the interview probe. However, over several conversational turns, they went on to identify fundamental limitations, such as how LLMs foreclose participants’ consent and agency, produce responses lacking in palpability and contextual depth, and risk delegitimizing qualitative research methods. We argue that the use of LLMs as proxies for participants enacts the surrogate effect, raising ethical and epistemological concerns that extend beyond the technical limitations of current models to the core of whether LLMs fit within qualitative ways of knowing.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {489},
numpages = {17},
keywords = {large language models, simulating research participants, LLM agents, qualitative research, LLMs in qualitative research, synthetic users, synthetic research data},
location = {
},
series = {CHI '25}
}